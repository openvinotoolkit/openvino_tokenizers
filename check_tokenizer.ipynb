{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pavel-esir/opt/envs/py312-ov-tokenizers/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/pavel-esir/opt/openvino_master/python/openvino/runtime/__init__.py:10: DeprecationWarning: The `openvino.runtime` module is deprecated and will be removed in the 2026.0 release. Please replace `openvino.runtime` with `openvino`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from openvino_tokenizers import convert_tokenizer\n",
    "import openvino as ov\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "core = ov.Core()\n",
    "\n",
    "model_id = \"microsoft/phi-1_5\"\n",
    "model_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "model_id = \"katuni4ka/tiny-random-llava-next\"\n",
    "model_id = \"answerdotai/ModernBERT-base\"\n",
    "\n",
    "hf_tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "# hf_tokenizer.save_pretrained(f'{model_id.split(\"/\")[1]}')\n",
    "ov_tokenizer, ov_detokenizer = convert_tokenizer(hf_tokenizer, with_detokenizer=True, number_of_inputs=2, max_length=20)\n",
    "# ov_tokenizer, ov_detokenizer = convert_tokenizer(hf_tokenizer, with_detokenizer=True)\n",
    "\n",
    "ov.save_model(ov_tokenizer, f'{model_id.split(\"/\")[1]}/openvino_tokenizer.xml')\n",
    "ov.save_model(ov_detokenizer, f'{model_id.split(\"/\")[1]}/openvino_detokenizer.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = core.compile_model(ov_tokenizer, \"CPU\")\n",
    "detokenizer = core.compile_model(ov_detokenizer, \"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ov_tokenizer.reshape(dict(Parameter_1=[2, 1], Parameter_2=[2, 1]))\n",
    "# ov_tokenizer.reshape(ov.PartialShape([2]))\n",
    "# ov.serialize(ov_tokenizer, \"tok.xml\")\n",
    "# tokenizer = core.compile_model(ov_tokenizer, \"CPU\")\n",
    "\n",
    "# from openvino import passes\n",
    "# pass_manager = passes.Manager()\n",
    "# pass_manager.register_pass(passes.VisualizeTree(file_name='image.svg'))\n",
    "# pass_manager.run_passes(ov_tokenizer)\n",
    "\n",
    "# inp_1 = ov.Tensor([\"hi\"])\n",
    "# inp_2 = ov.Tensor([\"sun in yellow\"])\n",
    "# # inp_2.set_shape([0])\n",
    "# tokenizer([[inp_1, inp_2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': array([[50281,  5801, 50282, 13998,   275,  8862, 50282]]), 'attention_mask': array([[1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_tokenizer([[\"hi\", \"sun in yellow\"]], return_tensors=\"np\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<ConstOutput: names[input_ids] shape[?,?] type: i64>: array([[50281,  5801, 50282, 13998,   275,  8862, 50282]]), <ConstOutput: names[attention_mask] shape[?,?] type: i64>: array([[1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer([[\"hi\", \"sun in yellow\"]])\n",
    "# [1, 2] for solution with reshape split\n",
    "\n",
    "# tokenizer([[\"hi\"], [\"sun in yellow\"]])\n",
    "# [2, 1] for solution with concat split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer([\"hi\", \"sun in yellow sdsf sdfsd 8892 sdfsk dssr 9sd 1k sd\"])[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<ConstOutput: names[input_ids] shape[?,?] type: i64>: array([[50281,  5801, 50282]]), <ConstOutput: names[attention_mask] shape[?,?] type: i64>: array([[1, 1, 1]])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer([[\"hi\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "Nx = 140\n",
    "Ny = 10\n",
    "get_seg = lambda N: ' '.join([chr(random.randint(0, 127)) for i in range(N)])\n",
    "x = get_seg(Nx)\n",
    "y = get_seg(Ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(279, 19)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[50281    74   209   194   247   500  3706  5042   416   259 50282   193\n",
      "    353   416   258   209   183   270 50275 50282]]\n",
      "------------------------------------------------------------\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "res_hf = hf_tokenizer([[x, y]], max_length=20, truncation=True, return_tensors=\"np\")['input_ids']\n",
    "res_ov = tokenizer([[x, y]])[0]\n",
    "res = res_hf\n",
    "\n",
    "print(res)\n",
    "print('------'*10)\n",
    "\n",
    "idx = np.nonzero(res[0] == 50282)[0][0]\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50281,    74,   209,   194,   247,   500,  3706,  5042,   416,\n",
       "          259, 50282,   193,   353,   416,   258,   209,   183,   270,\n",
       "        50275, 50282]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50281,    74,   209,   194,   247,   500,  3706,  5042,   416,\n",
       "          259, 50282,   193,   353,   416,   258,   209,   183,   270,\n",
       "        50275, 50282]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_ov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS]\\x07 : k @ ( P x + q [ ] *, Y @ k[SEP]\\x1b[SEP]'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_tokenizer.decode(res_hf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS]\\x07 : k @ ( P x + q[SEP]\\x1b|||IP_ADDRESS||||||IP_ADDRESS||||||IP_ADDRESS|||<|padding|>|||IP_ADDRESS||||||IP_ADDRESS|||[SEP]'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_tokenizer.decode(res_ov[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b\n"
     ]
    }
   ],
   "source": [
    "# print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]\u0007 : k @ ( P x + q [ ] *, Y @ k[SEP]\u001b[SEP]\n"
     ]
    }
   ],
   "source": [
    "decoded = hf_tokenizer.decode(res[0])\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded.count('s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded.count('h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50282]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_tokenizer.encode('[SEP]', add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single string can occupy more than 50% only if the second one is shorter than that.\n",
    "\n",
    "if sum is less than max length then no truncation.\n",
    "Select (sum <= max_length - num_added_tokens, x, slice(x, 0, len(x) // 2))\n",
    "\n",
    "opset.shape_of(x)\n",
    "opset.less(input_nodes[0], max_length).output(0),\n",
    "\n",
    "If sum > max_length\n",
    "\n",
    "x -> x[:len(x) // 2]\n",
    "y -> y[:len(y) // 2]\n",
    "\n",
    "Select\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312-ov-tokenizers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
